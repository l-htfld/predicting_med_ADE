{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP 2021 HW1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Три датасета с твитами: \n",
    "\n",
    "- тренировочный\n",
    "- тестовый\n",
    "- валидационный\n",
    "\n",
    "Нужно определить, какие твиты могут упоминать побочный эффекты от лекарств.\n",
    "\n",
    "Пайплайн:\n",
    "- Скачать все три датасета, определить их в переменные\n",
    "- Провести предобработку данных, почистить от пропусков, дупликатов.\n",
    "- Провести исследовательский аналих данных, выявить закономерности, если таковые имеются\n",
    "- Закодировать данные. Применить лингвистические трансформаторы (W2V, BoW, TF-IDF)\n",
    "- Подобрать модели, определить бейзлайн\n",
    "- Найти лучшую модель на тренировочной выборке, протестировать на тестовой и отправить на валидационную\n",
    "В\\- Вывести метрики качества, подвести итоги.\n",
    "\n",
    "Изменение для бранча."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simplemma in c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.9.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install simplemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import simplemma\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pickle\n",
    "import spacy\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.tsv', sep=\"\\t\")\n",
    "test_data = pd.read_csv('test.tsv', sep=\"\\t\")\n",
    "valid_data = pd.read_csv('valid.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_orig = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [train_data, test_data, valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Датасет: Train\n",
      "Первые 5 рядов:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>760402871867367424</td>\n",
       "      <td>Настало время для ингаляторов. Дружок, Сальбут...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1035908416869462016</td>\n",
       "      <td>15) На прошлой зимней олимпиаде большинство лы...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1089839736427032577</td>\n",
       "      <td>Не соглашусь с заменой ЗОК на метопролол в так...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779671488748224513</td>\n",
       "      <td>@di2m1 мезим Смекта Если отравление, то лоперамид</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>738309299756240897</td>\n",
       "      <td>Уберите микроволновки и имодиум  Действуют соу...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0   760402871867367424  Настало время для ингаляторов. Дружок, Сальбут...   \n",
       "1  1035908416869462016  15) На прошлой зимней олимпиаде большинство лы...   \n",
       "2  1089839736427032577  Не соглашусь с заменой ЗОК на метопролол в так...   \n",
       "3   779671488748224513  @di2m1 мезим Смекта Если отравление, то лоперамид   \n",
       "4   738309299756240897  Уберите микроволновки и имодиум  Действуют соу...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Размер: 8184 рядов x 3 колонок\n",
      "Пропущенные значения: 0\n",
      "\n",
      "Датасет: Test\n",
      "Первые 5 рядов:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1149390095612555266</td>\n",
       "      <td>от паксила такая дикая сонливость((</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1104439603304546304</td>\n",
       "      <td>@Kyzzenish Попробуйте парацетамол. Нередко оче...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5886509017</td>\n",
       "      <td>А для фанатов арбидола могу сообщить, что спон...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1539809930</td>\n",
       "      <td>Опять болит горло, поэтому опять забил на басс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>777843779021709312</td>\n",
       "      <td>У Васи жар, аж вся кровать и одеяло мокрые 😱 д...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet\n",
       "0  1149390095612555266                от паксила такая дикая сонливость((\n",
       "1  1104439603304546304  @Kyzzenish Попробуйте парацетамол. Нередко оче...\n",
       "2           5886509017  А для фанатов арбидола могу сообщить, что спон...\n",
       "3           1539809930  Опять болит горло, поэтому опять забил на басс...\n",
       "4   777843779021709312  У Васи жар, аж вся кровать и одеяло мокрые 😱 д..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Размер: 9095 рядов x 2 колонок\n",
      "Пропущенные значения: 0\n",
      "\n",
      "Датасет: Valid\n",
      "Первые 5 рядов:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1118138270830026754</td>\n",
       "      <td>@muuduckk Паксил на самом деле существует скол...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1098586199739023361</td>\n",
       "      <td>йебучий сука кветиапин ненавижу его всем сердц...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1107147495497519105</td>\n",
       "      <td>Оренбург : Алпразолам в оренбурге где можно ку...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1197120875964841984</td>\n",
       "      <td>@TakaSmoky Я как-то раз бросил миртазапин и ве...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>958998595390275585</td>\n",
       "      <td>Из того, что мне помогает выводить физически -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1118138270830026754  @muuduckk Паксил на самом деле существует скол...   \n",
       "1  1098586199739023361  йебучий сука кветиапин ненавижу его всем сердц...   \n",
       "2  1107147495497519105  Оренбург : Алпразолам в оренбурге где можно ку...   \n",
       "3  1197120875964841984  @TakaSmoky Я как-то раз бросил миртазапин и ве...   \n",
       "4   958998595390275585  Из того, что мне помогает выводить физически -...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Размер: 3425 рядов x 3 колонок\n",
      "Пропущенные значения: 0\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_info(datasets):\n",
    "    for name, data in zip(['Train', 'Test', 'Valid'], datas):\n",
    "        print(f\"\\nДатасет: {name}\")\n",
    "        print(\"Первые 5 рядов:\")\n",
    "        print(display(data.head()))\n",
    "        print(f\"Размер: {data.shape[0]} рядов x {data.shape[1]} колонок\")\n",
    "        print(f\"Пропущенные значения: {data.isnull().sum().sum()}\")\n",
    "\n",
    "datas = [train_data, test_data, valid_data]\n",
    "print_dataset_info(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные загружены. Пропусков нет ни в одном наборе. Нужно проверить на дупликаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Датасет: Train\n",
      "Количество дупликатов 0\n",
      "\n",
      "Датасет: Test\n",
      "Количество дупликатов 0\n",
      "\n",
      "Датасет: Valid\n",
      "Количество дупликатов 0\n"
     ]
    }
   ],
   "source": [
    "for name, data in zip(['Train', 'Test', 'Valid'], datas):\n",
    "    print(f\"\\nДатасет: {name}\")\n",
    "    print(f'Количество дупликатов {data.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные не содержат дупликатов ни айди, ни текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследовательский анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как нам дали только тексты твитов и целевой признак, то особо по графикам не разгуляемся. Но посмотрим на распределние классов, может надо будет сбалансировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,  2, figsize=(16,  6))\n",
    "\n",
    "datasets = [train_data, valid_data]\n",
    "titles = ['Train Dataset', 'Valid Dataset']\n",
    "\n",
    "for i, data in enumerate(datasets):\n",
    "    label_counts = data['label'].value_counts()\n",
    "    ratio = label_counts[0] / label_counts[1]\n",
    "    positions = ['Label   0', 'Label   1']\n",
    "    counts = [label_counts[0], label_counts[1]]\n",
    "    bar_width =  0.35\n",
    "\n",
    "    ax = axs[i]\n",
    "    rects = ax.bar(positions, counts, width=bar_width, color=['blue', 'orange'], edgecolor='black')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width() /  2, height, str(height), ha='center', va='bottom')\n",
    "\n",
    "    ax.set_xlabel('Label')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'{titles[i]}\\nСоотношение в Label   0 и Label   1: {ratio}')\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": [
           "rgb(58,  71,  80)",
           "rgb(255,  87,  51)"
          ]
         },
         "orientation": "v",
         "text": [
          "7411",
          "773"
         ],
         "type": "bar",
         "x": [
          "Label  0",
          "Label  1"
         ],
         "y": [
          7411,
          773
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of Labels"
        },
        "xaxis": {
         "title": {
          "text": "Label"
         }
        },
        "yaxis": {
         "title": {
          "text": "Count"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"cf636d96-7ce0-472b-a9b2-dcafa3679ea6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cf636d96-7ce0-472b-a9b2-dcafa3679ea6\")) {                    Plotly.newPlot(                        \"cf636d96-7ce0-472b-a9b2-dcafa3679ea6\",                        [{\"marker\":{\"color\":[\"rgb(58,  71,  80)\",\"rgb(255,  87,  51)\"]},\"orientation\":\"v\",\"text\":[\"7411\",\"773\"],\"x\":[\"Label  0\",\"Label  1\"],\"y\":[7411,773],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of Labels\"},\"xaxis\":{\"title\":{\"text\":\"Label\"}},\"yaxis\":{\"title\":{\"text\":\"Count\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('cf636d96-7ce0-472b-a9b2-dcafa3679ea6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = train_data['label'].value_counts()\n",
    "\n",
    "trace = go.Bar(\n",
    "    x=['Label  0', 'Label  1'],\n",
    "    y=[label_counts[0], label_counts[1]],\n",
    "    text=[label_counts[0], label_counts[1]],\n",
    "    marker=dict(\n",
    "        color=['rgb(58,  71,  80)', 'rgb(255,  87,  51)']\n",
    "    ),\n",
    "    orientation='v'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Distribution of Labels',\n",
    "    xaxis=dict(\n",
    "        title='Label'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Count'\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "iplot({'data': data, 'layout': layout})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных видим, то у нас один класс практически в 10 раз больше другого. Это может привести к недообучению модели, поэтому выборку неплохо было бы сбалансировать. Применим метод апсемлинга. Введем коэффициент (rat), который указывает, во сколько раз количество записей в классе с меткой 0 больше, чем количество записей в классе с меткой 1. Далее повторяем наименьший наименьший класс ровно rat раз, добавляем к датасету, смешиваем и приводим впорядок индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7411\n",
      "1    6957\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "rat = len(train_data.loc[train_data['label']==0]) // len(train_data.loc[train_data['label']==1])\n",
    "\n",
    "df_1 = train_data.loc[train_data['label']==1]\n",
    "df_1 = df_1.loc[df_1.index.repeat(rat)]\n",
    "\n",
    "train_data = pd.concat([train_data.loc[train_data['label']==0], df_1]).sample(frac=1)\n",
    "\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(train_data['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация, лемматизация, накидывание признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее займёмся featureendineering. Поделим твиты на токены, лематизируем, оставим основы, подсчитаем количество частей речи. Также заюзаем W2V."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('tweet_id', axis=1)\n",
    "test_data = test_data.drop('tweet_id', axis=1)\n",
    "valid_data = valid_data.drop('tweet_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lemmatize_token(tweet):\n",
    "    \n",
    "    '''Предобработка текста, удаление пунктуации, все символы к нижнему регистру, лемматизация слов'''\n",
    "\n",
    "    cleaned = tweet.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "    tokenized = word_tokenize(cleaned)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in tokenized]\n",
    "\n",
    "    lemmatized_text = ' '.join(lemmatized)\n",
    "    return lemmatized_text\n",
    "\n",
    "train_data['tweet'] = train_data['tweet'].apply(clean_lemmatize_token)\n",
    "test_data['tweet'] = test_data['tweet'].apply(clean_lemmatize_token)\n",
    "valid_data['tweet'] = valid_data['tweet'].apply(clean_lemmatize_token)\n",
    "\n",
    "def lemmatize_tweet(tweet):\n",
    "    \n",
    "    '''Лемматизация текста на русском языке'''\n",
    "    \n",
    "    tokens = tweet.split()\n",
    "\n",
    "    lemmatized_tokens = [simplemma.lemmatize(token, 'ru') for token in tokens]\n",
    "\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text\n",
    "\n",
    "train_data['lemmatized'] = train_data['tweet'].apply(lemmatize_tweet)\n",
    "test_data['lemmatized'] = test_data['tweet'].apply(lemmatize_tweet)\n",
    "valid_data['lemmatized'] = valid_data['tweet'].apply(lemmatize_tweet)\n",
    "\n",
    "def count_lemmas(lemmatized_text):\n",
    "    \n",
    "    '''Подсчёт лемм'''\n",
    "    \n",
    "    words = lemmatized_text.split()\n",
    "    return len(words)\n",
    "\n",
    "def count_pos_tags(lemmatized_text, pos_tags):\n",
    "    \n",
    "    '''Подсчёт количества слов с заданными частями речи в тексте'''\n",
    "    \n",
    "    tagged_words = pos_tag(word_tokenize(lemmatized_text))\n",
    "    return sum(1 for word, tag in tagged_words if tag in pos_tags)\n",
    "\n",
    "noun_pos_tags = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "verb_pos_tags = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "adjective_pos_tags = ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def count_unique_lemmas(text):\n",
    "    \n",
    "    '''Подсчёт уникальных лемм в тексте'''\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    unique_lemmas_count = len(Counter(lemmas))\n",
    "    return unique_lemmas_count\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def porter_stem_tweet(tweet):\n",
    "    \n",
    "    '''Стеминг текста'''\n",
    "    \n",
    "    tokens = tweet.split()\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    stemmed_text = ' '.join(stemmed_tokens)\n",
    "    return stemmed_text\n",
    "\n",
    "def text_to_embedding(text):\n",
    "    \n",
    "    '''Преобразование текста в вектора'''\n",
    "    \n",
    "    words = text.split()\n",
    "    embeddings = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('tweet', axis=1)\n",
    "test_data = test_data.drop('tweet', axis=1)\n",
    "valid_data = valid_data.drop('tweet', axis=1)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "valid_data = valid_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tweets = train_data['lemmatized'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['num_lemmas'] = train_data['lemmatized'].apply(count_lemmas)\n",
    "test_data['num_lemmas'] = test_data['lemmatized'].apply(count_lemmas)\n",
    "\n",
    "train_data['num_nouns'] = train_data['lemmatized'].apply(lambda x: count_pos_tags(x, noun_pos_tags))\n",
    "train_data['num_verbs'] = train_data['lemmatized'].apply(lambda x: count_pos_tags(x, verb_pos_tags))\n",
    "train_data['num_adjectives'] = train_data['lemmatized'].apply(lambda x: count_pos_tags(x, adjective_pos_tags))\n",
    "\n",
    "test_data['num_nouns'] = test_data['lemmatized'].apply(lambda x: count_pos_tags(x, noun_pos_tags))\n",
    "test_data['num_verbs'] = test_data['lemmatized'].apply(lambda x: count_pos_tags(x, verb_pos_tags))\n",
    "test_data['num_adjectives'] = test_data['lemmatized'].apply(lambda x: count_pos_tags(x, adjective_pos_tags))\n",
    "\n",
    "valid_data['num_lemmas'] = valid_data['lemmatized'].apply(count_lemmas)\n",
    "\n",
    "valid_data['num_nouns'] = valid_data['lemmatized'].apply(lambda x: count_pos_tags(x, noun_pos_tags))\n",
    "valid_data['num_verbs'] = valid_data['lemmatized'].apply(lambda x: count_pos_tags(x, verb_pos_tags))\n",
    "valid_data['num_adjectives'] = valid_data['lemmatized'].apply(lambda x: count_pos_tags(x, adjective_pos_tags))\n",
    "\n",
    "train_data['num_pronouns'] = train_data['lemmatized'].apply(lambda x: count_pos_tags(x, ['PRON']))\n",
    "test_data['num_pronouns'] = test_data['lemmatized'].apply(lambda x: count_pos_tags(x, ['PRON']))\n",
    "valid_data['num_pronouns'] = valid_data['lemmatized'].apply(lambda x: count_pos_tags(x, ['PRON']))\n",
    "\n",
    "train_data['num_adverbs'] = train_data['lemmatized'].apply(lambda x: count_pos_tags(x, ['ADV']))\n",
    "test_data['num_adverbs'] = test_data['lemmatized'].apply(lambda x: count_pos_tags(x, ['ADV']))\n",
    "valid_data['num_adverbs'] = valid_data['lemmatized'].apply(lambda x: count_pos_tags(x, ['ADV']))\n",
    "\n",
    "train_data['num_prepositions'] = train_data['lemmatized'].apply(lambda x: count_pos_tags(x, ['ADP']))\n",
    "test_data['num_prepositions'] = test_data['lemmatized'].apply(lambda x: count_pos_tags(x, ['ADP']))\n",
    "valid_data['num_prepositions'] = valid_data['lemmatized'].apply(lambda x: count_pos_tags(x, ['ADP']))\n",
    "\n",
    "train_data['num_unique_lemmas'] = train_data['lemmatized'].apply(count_unique_lemmas)\n",
    "test_data['num_unique_lemmas'] = test_data['lemmatized'].apply(count_unique_lemmas)\n",
    "valid_data['num_unique_lemmas'] = valid_data['lemmatized'].apply(count_unique_lemmas)\n",
    "\n",
    "train_data['porter_stemmed'] = train_data['lemmatized'].apply(porter_stem_tweet)\n",
    "test_data['porter_stemmed'] = test_data['lemmatized'].apply(porter_stem_tweet)\n",
    "valid_data['porter_stemmed'] = valid_data['lemmatized'].apply(porter_stem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('lemmatized', axis=1)\n",
    "test_data = test_data.drop('lemmatized', axis=1)\n",
    "valid_data = valid_data.drop('lemmatized', axis=1)\n",
    "\n",
    "train_data.rename(columns={'porter_stemmed': 'lemmatized'}, inplace=True)\n",
    "test_data.rename(columns={'porter_stemmed': 'lemmatized'}, inplace=True)\n",
    "valid_data.rename(columns={'porter_stemmed': 'lemmatized'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweets = train_data['lemmatized'].apply(lambda x: x.split())\n",
    "word2vec_model = Word2Vec(sentences=tokenized_tweets, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = np.vstack(X_train['lemmatized'].apply(text_to_embedding))\n",
    "X_test_word2vec = np.vstack(X_test['lemmatized'].apply(text_to_embedding))\n",
    "X_valid_word2vec = np.vstack(X_valid['lemmatized'].apply(text_to_embedding))\n",
    "\n",
    "train_data = pd.concat([train_data, pd.DataFrame(X_train_word2vec)], axis=1) #объединяем вектора с данными в датасете\n",
    "test_data = pd.concat([test_data, pd.DataFrame(X_test_word2vec)], axis=1)\n",
    "valid_data = pd.concat([valid_data, pd.DataFrame(X_test_word2vec)], axis=1)\n",
    "\n",
    "train_data.fillna(0, inplace=True)\n",
    "test_data.fillna(0, inplace=True)\n",
    "valid_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь переходим к обучению моделей. Текст разбиваем на тренировочную и тестовые выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('label', axis=1)\n",
    "y = train_data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11494, 109)\n",
      "(2874, 109)\n",
      "(11494,)\n",
      "(2874,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_lemmas</th>\n",
       "      <th>num_nouns</th>\n",
       "      <th>num_verbs</th>\n",
       "      <th>num_adjectives</th>\n",
       "      <th>num_pronouns</th>\n",
       "      <th>num_adverbs</th>\n",
       "      <th>num_prepositions</th>\n",
       "      <th>num_unique_lemmas</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8247</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>интересный побочка от ламотриджин не мочь слад...</td>\n",
       "      <td>-0.404736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642771</td>\n",
       "      <td>0.257990</td>\n",
       "      <td>0.078146</td>\n",
       "      <td>0.134421</td>\n",
       "      <td>0.810009</td>\n",
       "      <td>0.478324</td>\n",
       "      <td>0.100386</td>\n",
       "      <td>-0.320472</td>\n",
       "      <td>0.116837</td>\n",
       "      <td>-0.105944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13596</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>сальбутамол в голова ударить не рассчитать доза</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>я пачка есть феназепам у меня диагноз но от се...</td>\n",
       "      <td>-0.472271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800177</td>\n",
       "      <td>0.245626</td>\n",
       "      <td>-0.096916</td>\n",
       "      <td>0.110806</td>\n",
       "      <td>0.989008</td>\n",
       "      <td>0.402261</td>\n",
       "      <td>0.060305</td>\n",
       "      <td>-0.528013</td>\n",
       "      <td>0.058411</td>\n",
       "      <td>-0.086609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13262</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>кветиапин почему ты така жестокий еще только 2...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>кроме тот что высокий доза прозака порождать п...</td>\n",
       "      <td>-0.388932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848021</td>\n",
       "      <td>0.202059</td>\n",
       "      <td>-0.047772</td>\n",
       "      <td>0.067175</td>\n",
       "      <td>0.991364</td>\n",
       "      <td>0.386252</td>\n",
       "      <td>-0.007799</td>\n",
       "      <td>-0.466347</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>-0.033447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>да у меня закончиться курс флуоксетина сильный...</td>\n",
       "      <td>-0.586438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854336</td>\n",
       "      <td>0.318982</td>\n",
       "      <td>-0.090158</td>\n",
       "      <td>0.209664</td>\n",
       "      <td>1.036224</td>\n",
       "      <td>0.572233</td>\n",
       "      <td>0.060834</td>\n",
       "      <td>-0.612618</td>\n",
       "      <td>0.086986</td>\n",
       "      <td>-0.083254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>aalien gtи да я в депрессия венлафаксин 300мгс...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>присниться шо закинуться ксанаксом в аптека</td>\n",
       "      <td>-0.611085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969584</td>\n",
       "      <td>0.355296</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.198648</td>\n",
       "      <td>1.061168</td>\n",
       "      <td>0.535623</td>\n",
       "      <td>0.120014</td>\n",
       "      <td>-0.511037</td>\n",
       "      <td>0.107483</td>\n",
       "      <td>-0.131283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>на совещание рассказать как дитя траванулись б...</td>\n",
       "      <td>-0.528755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771560</td>\n",
       "      <td>0.295881</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>0.108926</td>\n",
       "      <td>0.932827</td>\n",
       "      <td>0.524666</td>\n",
       "      <td>0.105029</td>\n",
       "      <td>-0.451394</td>\n",
       "      <td>0.043812</td>\n",
       "      <td>-0.158478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>тогда уж хороший фенибут и флуоксетин</td>\n",
       "      <td>-0.635612</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027478</td>\n",
       "      <td>0.353154</td>\n",
       "      <td>-0.072162</td>\n",
       "      <td>0.167544</td>\n",
       "      <td>1.342673</td>\n",
       "      <td>0.517930</td>\n",
       "      <td>0.087562</td>\n",
       "      <td>-0.682186</td>\n",
       "      <td>0.191092</td>\n",
       "      <td>-0.113539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11494 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_lemmas  num_nouns  num_verbs  num_adjectives  num_pronouns  \\\n",
       "8247           18         17          0               1             0   \n",
       "13596           7          6          0               1             0   \n",
       "3822           21         18          1               1             0   \n",
       "13262          13         11          0               1             0   \n",
       "6086           30         29          0               1             0   \n",
       "...           ...        ...        ...             ...           ...   \n",
       "5191            8          7          0               1             0   \n",
       "13418          15         12          1               0             0   \n",
       "5390            6          5          0               1             0   \n",
       "860            18         17          0               1             0   \n",
       "7270            6          5          0               1             0   \n",
       "\n",
       "       num_adverbs  num_prepositions  num_unique_lemmas  \\\n",
       "8247             0                 0                 16   \n",
       "13596            0                 0                  7   \n",
       "3822             0                 0                 19   \n",
       "13262            0                 0                 13   \n",
       "6086             0                 0                 28   \n",
       "...            ...               ...                ...   \n",
       "5191             0                 0                  8   \n",
       "13418            0                 0                 15   \n",
       "5390             0                 0                  6   \n",
       "860              0                 0                 17   \n",
       "7270             0                 0                  6   \n",
       "\n",
       "                                              lemmatized         0  ...  \\\n",
       "8247   интересный побочка от ламотриджин не мочь слад... -0.404736  ...   \n",
       "13596    сальбутамол в голова ударить не рассчитать доза  0.000000  ...   \n",
       "3822   я пачка есть феназепам у меня диагноз но от се... -0.472271  ...   \n",
       "13262  кветиапин почему ты така жестокий еще только 2...  0.000000  ...   \n",
       "6086   кроме тот что высокий доза прозака порождать п... -0.388932  ...   \n",
       "...                                                  ...       ...  ...   \n",
       "5191   да у меня закончиться курс флуоксетина сильный... -0.586438  ...   \n",
       "13418  aalien gtи да я в депрессия венлафаксин 300мгс...  0.000000  ...   \n",
       "5390         присниться шо закинуться ксанаксом в аптека -0.611085  ...   \n",
       "860    на совещание рассказать как дитя траванулись б... -0.528755  ...   \n",
       "7270               тогда уж хороший фенибут и флуоксетин -0.635612  ...   \n",
       "\n",
       "             90        91        92        93        94        95        96  \\\n",
       "8247   0.642771  0.257990  0.078146  0.134421  0.810009  0.478324  0.100386   \n",
       "13596  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3822   0.800177  0.245626 -0.096916  0.110806  0.989008  0.402261  0.060305   \n",
       "13262  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6086   0.848021  0.202059 -0.047772  0.067175  0.991364  0.386252 -0.007799   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "5191   0.854336  0.318982 -0.090158  0.209664  1.036224  0.572233  0.060834   \n",
       "13418  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5390   0.969584  0.355296  0.010099  0.198648  1.061168  0.535623  0.120014   \n",
       "860    0.771560  0.295881  0.045702  0.108926  0.932827  0.524666  0.105029   \n",
       "7270   1.027478  0.353154 -0.072162  0.167544  1.342673  0.517930  0.087562   \n",
       "\n",
       "             97        98        99  \n",
       "8247  -0.320472  0.116837 -0.105944  \n",
       "13596  0.000000  0.000000  0.000000  \n",
       "3822  -0.528013  0.058411 -0.086609  \n",
       "13262  0.000000  0.000000  0.000000  \n",
       "6086  -0.466347  0.008983 -0.033447  \n",
       "...         ...       ...       ...  \n",
       "5191  -0.612618  0.086986 -0.083254  \n",
       "13418  0.000000  0.000000  0.000000  \n",
       "5390  -0.511037  0.107483 -0.131283  \n",
       "860   -0.451394  0.043812 -0.158478  \n",
       "7270  -0.682186  0.191092 -0.113539  \n",
       "\n",
       "[11494 rows x 109 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8247     1\n",
       "13596    0\n",
       "3822     1\n",
       "13262    1\n",
       "6086     1\n",
       "        ..\n",
       "5191     0\n",
       "13418    0\n",
       "5390     0\n",
       "860      1\n",
       "7270     0\n",
       "Name: label, Length: 11494, dtype: int64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно применить TF-IDF, StandartScaler и BoW отдельно к столбцу с леммами. Для этого воспользуемся трансформером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = set(stopwords.words('russian'))\n",
    "numerical_features = ['num_lemmas', 'num_nouns', 'num_verbs', 'num_adjectives', 'num_unique_lemmas']\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('lemmatized_tfidf', TfidfVectorizer(max_features=1000, ngram_range=(1, 2), stop_words=custom_stop_words), 'lemmatized'),\n",
    "        ('numerical_scaler', StandardScaler(), numerical_features),\n",
    "        ('bag_of_words', CountVectorizer(max_features=1000, ngram_range=(1, 2), stop_words=custom_stop_words), 'lemmatized')\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning:\n",
      "\n",
      "Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_encoded = transformer.fit_transform(X_train)\n",
    "X_test_encoded = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11494, 2108)\n",
      "(2874, 2108)\n",
      "(11494,)\n",
      "(2874,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded.shape)\n",
    "print(X_test_encoded.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные готовы. Можно переходить к моделям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.9437319605602152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_encoded, y_train)\n",
    "y_pred = model.predict_proba(X_test_encoded)[:,  1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC-AUC Score:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия показала высокую оценку ROC-AUC. Но нам нужно взять более подходящую модель для оценок, так как на тесте все может быть иначе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0,  1], [0,  1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0,  1.0])\n",
    "plt.ylim([0.0,  1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбираем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи классификации в NLP хорошо бы подошёл метод опорных векторов, так как он хорошо работает в пространствах высокой размерности, хорошо работает с разреженными матрицами и подходяит для работы с векторами.\n",
    "\n",
    "Также я еще выбрал LightGBM, потому что он может достигнуть высокой точности классификации ис спосбен моделировать сложные нелинейные зависимости, а нам это и надо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV 1/3] END C=0.1, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.945 total time=   0.8s\n",
      "[CV 2/3] END C=0.1, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.946 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.943 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.945 total time=   0.5s\n",
      "[CV 2/3] END C=0.1, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.946 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.943 total time=   0.5s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.945 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.946 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.943 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.945 total time=   0.5s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.946 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.943 total time=   0.4s\n",
      "[CV 1/3] END C=0.5, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.948 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.5, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.948 total time=   2.8s\n",
      "[CV 3/3] END C=0.5, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.948 total time=   2.1s\n",
      "[CV 1/3] END C=0.5, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.948 total time=   0.7s\n",
      "[CV 2/3] END C=0.5, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.948 total time=   0.7s\n",
      "[CV 3/3] END C=0.5, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.948 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.5, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.948 total time=   3.0s\n",
      "[CV 2/3] END C=0.5, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.948 total time=   2.5s\n",
      "[CV 3/3] END C=0.5, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.948 total time=   2.1s\n",
      "[CV 1/3] END C=0.5, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.948 total time=   0.8s\n",
      "[CV 2/3] END C=0.5, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.948 total time=   0.8s\n",
      "[CV 3/3] END C=0.5, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.948 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.948 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.947 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.947 total time=   2.4s\n",
      "[CV 1/3] END C=1, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.948 total time=   0.8s\n",
      "[CV 2/3] END C=1, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.947 total time=   0.8s\n",
      "[CV 3/3] END C=1, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.947 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.948 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.947 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.948 total time=   2.8s\n",
      "[CV 1/3] END C=1, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.948 total time=   0.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.947 total time=   0.8s\n",
      "[CV 3/3] END C=1, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.948 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1.5, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.947 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1.5, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.947 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1.5, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.946 total time=   2.0s\n",
      "[CV 1/3] END C=1.5, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.947 total time=   0.9s\n",
      "[CV 2/3] END C=1.5, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.947 total time=   0.9s\n",
      "[CV 3/3] END C=1.5, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.946 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1.5, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.947 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1.5, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.947 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1.5, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.946 total time=   2.5s\n",
      "[CV 1/3] END C=1.5, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.947 total time=   1.3s\n",
      "[CV 2/3] END C=1.5, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.947 total time=   1.1s\n",
      "[CV 3/3] END C=1.5, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.946 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=2, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.947 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=2, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.946 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=2, class_weight=None, dual=True, loss=squared_hinge, penalty=l2;, score=0.945 total time=   2.4s\n",
      "[CV 1/3] END C=2, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.947 total time=   1.0s\n",
      "[CV 2/3] END C=2, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.946 total time=   1.2s\n",
      "[CV 3/3] END C=2, class_weight=None, dual=False, loss=squared_hinge, penalty=l2;, score=0.945 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=2, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.947 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=2, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.946 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=2, class_weight=balanced, dual=True, loss=squared_hinge, penalty=l2;, score=0.946 total time=   2.0s\n",
      "[CV 1/3] END C=2, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.947 total time=   1.2s\n",
      "[CV 2/3] END C=2, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.946 total time=   1.3s\n",
      "[CV 3/3] END C=2, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2;, score=0.946 total time=   1.5s\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1, 1.5, 2],\n",
    "    'penalty': ['l2'],\n",
    "    'loss': ['squared_hinge'],\n",
    "    'dual': [True, False],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "model = LinearSVC(random_state=RANDOM_STATE)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3, n_jobs=1, verbose=3)\n",
    "grid_result_svm = grid_search.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший: 0.947982 при {'C': 0.5, 'class_weight': 'balanced', 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.945 (+/-0.003) with: {'C': 0.1, 'class_weight': None, 'dual': True, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.945 (+/-0.003) with: {'C': 0.1, 'class_weight': None, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.945 (+/-0.003) with: {'C': 0.1, 'class_weight': 'balanced', 'dual': True, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.945 (+/-0.003) with: {'C': 0.1, 'class_weight': 'balanced', 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.948 (+/-0.000) with: {'C': 0.5, 'class_weight': None, 'dual': True, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.948 (+/-0.000) with: {'C': 0.5, 'class_weight': None, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.948 (+/-0.000) with: {'C': 0.5, 'class_weight': 'balanced', 'dual': True, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.948 (+/-0.000) with: {'C': 0.5, 'class_weight': 'balanced', 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.947 (+/-0.001) with: {'C': 1, 'class_weight': None, 'dual': True, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.947 (+/-0.001) with: {'C': 1, 'class_weight': None, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.947 (+/-0.001) with: {'C': 1, 'class_weight': 'balanced', 'dual': True, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.947 (+/-0.001) with: {'C': 1, 'class_weight': 'balanced', 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.947 (+/-0.001) with: {'C': 1.5, 'class_weight': None, 'dual': True, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.947 (+/-0.001) with: {'C': 1.5, 'class_weight': None, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.947 (+/-0.001) with: {'C': 1.5, 'class_weight': 'balanced', 'dual': True, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.947 (+/-0.001) with: {'C': 1.5, 'class_weight': 'balanced', 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.946 (+/-0.001) with: {'C': 2, 'class_weight': None, 'dual': True, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.946 (+/-0.001) with: {'C': 2, 'class_weight': None, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.946 (+/-0.001) with: {'C': 2, 'class_weight': 'balanced', 'dual': True, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "0.946 (+/-0.001) with: {'C': 2, 'class_weight': 'balanced', 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Лучший: %f при %s\" % (grid_result_svm.best_score_, grid_result_svm.best_params_))\n",
    "\n",
    "means = grid_result_svm.cv_results_['mean_test_score']\n",
    "stds = grid_result_svm.cv_results_['std_test_score']\n",
    "params = grid_result_svm.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(\"%0.3f (+/-%0.03f) with: %r\" % (mean, std *  2, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC-AUC Score:  0.9095337508698678\n"
     ]
    }
   ],
   "source": [
    "best_model_svm = grid_result_svm.best_estimator_\n",
    "best_model_svm.fit(X_train_encoded, y_train)\n",
    "\n",
    "test_score = best_model_svm.score(X_test_encoded, y_test)\n",
    "\n",
    "print(\"Test ROC-AUC Score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = valid_data.drop('label', axis=1)\n",
    "y_valid = valid_data['label']\n",
    "X_valid_encoded = transformer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC Score:  0.8172262773722627\n"
     ]
    }
   ],
   "source": [
    "valid_score = best_model_svm.score(X_valid_encoded, y_valid)\n",
    "print(\"Validation ROC-AUC Score: \", valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По оценкам на тестовой выборки SVM хорошо себя показала в плане предсказания. Посмотрим что выдаст LGBMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.15;, score=0.859 total time=   6.0s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.15;, score=0.866 total time=   6.1s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.15;, score=0.863 total time=  10.7s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.2;, score=0.860 total time=  13.6s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.2;, score=0.866 total time=  10.9s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.2;, score=0.863 total time=   6.8s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.25;, score=0.858 total time=   6.3s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.25;, score=0.864 total time=   6.6s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.25;, score=0.862 total time=   6.4s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.5;, score=0.855 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.5;, score=0.863 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=0.5;, score=0.860 total time=   6.9s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=1;, score=0.852 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=1;, score=0.859 total time=   6.7s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=700, reg_lambda=1;, score=0.857 total time=   5.8s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.15;, score=0.867 total time=   7.7s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.15;, score=0.875 total time=   7.5s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.15;, score=0.872 total time=   9.3s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.2;, score=0.867 total time=  11.2s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.2;, score=0.875 total time=  10.2s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.2;, score=0.871 total time=   9.2s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.25;, score=0.866 total time=  11.1s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.25;, score=0.874 total time=  11.7s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.25;, score=0.871 total time=  12.0s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.5;, score=0.863 total time=   8.0s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.5;, score=0.872 total time=   9.0s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=0.5;, score=0.868 total time=   9.0s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=1;, score=0.859 total time=   7.6s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=1;, score=0.868 total time=  10.8s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=800, reg_lambda=1;, score=0.865 total time=   9.8s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.15;, score=0.873 total time=  16.4s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.15;, score=0.883 total time=  17.4s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.15;, score=0.879 total time=  12.5s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.2;, score=0.873 total time=  11.8s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.2;, score=0.883 total time=  10.5s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.2;, score=0.878 total time=   8.7s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.25;, score=0.872 total time=   8.2s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.25;, score=0.881 total time=   8.2s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.25;, score=0.878 total time=  12.7s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.5;, score=0.869 total time=   8.3s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.5;, score=0.880 total time=   8.5s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=0.5;, score=0.875 total time=   8.2s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=1;, score=0.866 total time=   8.7s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=1;, score=0.876 total time=   7.2s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=900, reg_lambda=1;, score=0.871 total time=   8.0s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.15;, score=0.882 total time=   8.8s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.15;, score=0.893 total time=   8.2s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.15;, score=0.887 total time=   8.1s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.2;, score=0.881 total time=  10.4s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.2;, score=0.893 total time=  10.5s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.2;, score=0.887 total time=   8.8s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.25;, score=0.881 total time=  10.6s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.25;, score=0.893 total time=  10.9s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.25;, score=0.886 total time=   9.2s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.5;, score=0.878 total time=   9.0s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.5;, score=0.891 total time=   8.7s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=0.5;, score=0.883 total time=   8.8s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=1;, score=0.874 total time=   9.1s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=1;, score=0.887 total time=   7.5s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=700, reg_lambda=1;, score=0.879 total time=   7.8s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.15;, score=0.889 total time=  18.9s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.15;, score=0.901 total time=  15.8s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.15;, score=0.894 total time=  10.9s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.2;, score=0.888 total time=  12.5s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.2;, score=0.902 total time=  10.9s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.2;, score=0.894 total time=   8.7s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.25;, score=0.888 total time=   9.9s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.25;, score=0.900 total time=   8.5s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.25;, score=0.893 total time=   8.7s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.5;, score=0.885 total time=  11.7s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.5;, score=0.899 total time=  10.4s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=0.5;, score=0.890 total time=   8.6s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=1;, score=0.881 total time=  14.9s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=1;, score=0.895 total time=   9.6s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=800, reg_lambda=1;, score=0.886 total time=   8.9s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.15;, score=0.895 total time=  10.2s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.15;, score=0.908 total time=  11.8s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.15;, score=0.900 total time=  13.0s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.2;, score=0.894 total time=  11.4s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.2;, score=0.908 total time=  11.8s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.2;, score=0.900 total time=  12.4s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.25;, score=0.894 total time=  11.6s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.25;, score=0.907 total time=  12.4s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.25;, score=0.900 total time=  12.4s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.5;, score=0.891 total time=  11.7s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.5;, score=0.906 total time=  11.1s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=0.5;, score=0.897 total time=  11.3s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=1;, score=0.887 total time=  11.1s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=1;, score=0.902 total time=  10.9s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=7, n_estimators=900, reg_lambda=1;, score=0.892 total time=  11.7s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.15;, score=0.939 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.15;, score=0.951 total time=   5.6s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.15;, score=0.940 total time=   5.5s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.2;, score=0.939 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.2;, score=0.951 total time=   5.4s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.2;, score=0.940 total time=   5.4s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.25;, score=0.940 total time=   5.6s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.25;, score=0.950 total time=   5.5s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.25;, score=0.940 total time=   5.9s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.5;, score=0.938 total time=   6.0s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.5;, score=0.949 total time=   6.1s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=0.5;, score=0.939 total time=   5.5s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=1;, score=0.932 total time=   5.4s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=1;, score=0.946 total time=   5.3s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=700, reg_lambda=1;, score=0.935 total time=   5.4s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.15;, score=0.944 total time=   6.3s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.15;, score=0.956 total time=   6.2s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.15;, score=0.945 total time=   6.2s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.2;, score=0.944 total time=   6.5s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.2;, score=0.955 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.2;, score=0.944 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.25;, score=0.944 total time=   6.1s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.25;, score=0.955 total time=   6.0s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.25;, score=0.944 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.5;, score=0.942 total time=   6.1s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.5;, score=0.954 total time=   6.0s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=0.5;, score=0.943 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=1;, score=0.937 total time=   6.4s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=1;, score=0.951 total time=   6.2s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=800, reg_lambda=1;, score=0.940 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.15;, score=0.948 total time=   6.9s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.15;, score=0.959 total time=   7.0s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.15;, score=0.948 total time=   6.9s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.2;, score=0.948 total time=   7.1s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.2;, score=0.959 total time=   6.8s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.2;, score=0.948 total time=   6.8s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.25;, score=0.947 total time=   7.1s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.25;, score=0.958 total time=   6.8s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.25;, score=0.948 total time=   7.0s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.5;, score=0.945 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.5;, score=0.958 total time=   6.7s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=0.5;, score=0.947 total time=   6.9s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=1;, score=0.941 total time=   6.7s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=1;, score=0.954 total time=   7.3s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=900, reg_lambda=1;, score=0.943 total time=   7.0s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.15;, score=0.953 total time=   8.3s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.15;, score=0.964 total time=   7.5s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.15;, score=0.954 total time=   7.4s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.2;, score=0.952 total time=   7.6s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.2;, score=0.964 total time=   7.4s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.2;, score=0.953 total time=   7.5s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.25;, score=0.952 total time=   7.3s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.25;, score=0.963 total time=   7.4s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.25;, score=0.951 total time=   7.5s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.5;, score=0.951 total time=   7.7s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.5;, score=0.962 total time=   7.5s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=0.5;, score=0.950 total time=   7.4s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=1;, score=0.946 total time=   7.7s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=1;, score=0.959 total time=   7.3s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=700, reg_lambda=1;, score=0.947 total time=   7.2s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.15;, score=0.956 total time=   8.5s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.15;, score=0.967 total time=   8.3s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.15;, score=0.957 total time=   8.3s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.2;, score=0.955 total time=   8.6s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.2;, score=0.967 total time=   8.2s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.2;, score=0.956 total time=   8.3s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.25;, score=0.955 total time=   8.5s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.25;, score=0.966 total time=   8.2s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.25;, score=0.955 total time=   8.5s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.5;, score=0.955 total time=   8.4s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.5;, score=0.965 total time=   8.3s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=0.5;, score=0.954 total time=   8.7s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=1;, score=0.950 total time=   9.0s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=1;, score=0.962 total time=   8.5s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=800, reg_lambda=1;, score=0.951 total time=   8.4s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.15;, score=0.959 total time=   9.5s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.15;, score=0.970 total time=   9.5s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.15;, score=0.960 total time=   9.4s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.2;, score=0.958 total time=  11.6s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.2;, score=0.969 total time=  11.8s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.2;, score=0.959 total time=  10.0s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.25;, score=0.958 total time=   9.5s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.25;, score=0.969 total time=   9.1s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.25;, score=0.958 total time=   9.5s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.5;, score=0.957 total time=   9.1s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.5;, score=0.968 total time=   9.0s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=0.5;, score=0.957 total time=   9.6s\n",
      "[CV 1/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=1;, score=0.953 total time=   9.2s\n",
      "[CV 2/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=1;, score=0.965 total time=   9.3s\n",
      "[CV 3/3] END learning_rate=0.05, max_depth=7, n_estimators=900, reg_lambda=1;, score=0.954 total time=   9.5s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.15;, score=0.960 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.15;, score=0.970 total time=   5.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.15;, score=0.961 total time=   5.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.2;, score=0.960 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.2;, score=0.969 total time=   5.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.2;, score=0.960 total time=   6.0s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.25;, score=0.958 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.25;, score=0.969 total time=   5.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.25;, score=0.960 total time=   5.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.5;, score=0.958 total time=   5.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.5;, score=0.968 total time=   5.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=0.5;, score=0.958 total time=   5.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=1;, score=0.954 total time=   5.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=1;, score=0.964 total time=   5.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=700, reg_lambda=1;, score=0.955 total time=   5.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.15;, score=0.962 total time=   6.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.15;, score=0.972 total time=   6.8s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.15;, score=0.964 total time=   7.0s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.2;, score=0.962 total time=   6.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.2;, score=0.972 total time=   6.9s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.2;, score=0.963 total time=   6.5s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.25;, score=0.961 total time=   6.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.25;, score=0.972 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.25;, score=0.962 total time=   6.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.5;, score=0.961 total time=   6.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.5;, score=0.971 total time=   6.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=0.5;, score=0.961 total time=   6.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=1;, score=0.956 total time=   6.7s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=1;, score=0.967 total time=   6.6s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=800, reg_lambda=1;, score=0.959 total time=   6.3s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.15;, score=0.965 total time=   7.1s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.15;, score=0.973 total time=   7.2s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.15;, score=0.966 total time=   7.1s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.2;, score=0.965 total time=   7.1s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.2;, score=0.973 total time=   7.3s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.2;, score=0.964 total time=   7.2s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.25;, score=0.963 total time=   7.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.25;, score=0.973 total time=   7.0s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.25;, score=0.964 total time=   7.1s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.5;, score=0.963 total time=   7.1s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.5;, score=0.972 total time=   6.9s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=0.5;, score=0.963 total time=   7.5s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=1;, score=0.959 total time=   7.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=1;, score=0.969 total time=   7.1s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=900, reg_lambda=1;, score=0.961 total time=   7.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.15;, score=0.966 total time=   7.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.15;, score=0.975 total time=   7.6s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.15;, score=0.968 total time=   7.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.2;, score=0.965 total time=   7.3s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.2;, score=0.975 total time=   7.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.2;, score=0.967 total time=   7.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.25;, score=0.965 total time=   7.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.25;, score=0.975 total time=   7.8s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.25;, score=0.966 total time=   7.2s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.5;, score=0.964 total time=   7.2s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.5;, score=0.974 total time=   7.6s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=0.5;, score=0.965 total time=   7.2s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=1;, score=0.962 total time=   7.1s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=1;, score=0.973 total time=   7.1s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=700, reg_lambda=1;, score=0.963 total time=   7.1s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.15;, score=0.968 total time=   9.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.15;, score=0.976 total time=   8.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.15;, score=0.969 total time=   8.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.2;, score=0.966 total time=   8.7s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.2;, score=0.977 total time=   8.6s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.2;, score=0.969 total time=   8.8s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.25;, score=0.967 total time=   8.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.25;, score=0.976 total time=   8.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.25;, score=0.968 total time=   9.0s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.5;, score=0.966 total time=   8.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.5;, score=0.976 total time=   8.8s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=0.5;, score=0.967 total time=   8.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=1;, score=0.964 total time=   9.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=1;, score=0.974 total time=   8.6s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=800, reg_lambda=1;, score=0.965 total time=   8.8s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.15;, score=0.969 total time=   9.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.15;, score=0.978 total time=  10.0s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.15;, score=0.971 total time=   9.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.2;, score=0.968 total time=   9.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.2;, score=0.978 total time=  10.0s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.2;, score=0.970 total time=  10.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.25;, score=0.968 total time=   9.8s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.25;, score=0.977 total time=   9.8s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.25;, score=0.970 total time=   9.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.5;, score=0.968 total time=  10.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.5;, score=0.977 total time=   9.7s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=0.5;, score=0.968 total time=   9.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=1;, score=0.965 total time=   9.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=1;, score=0.976 total time=   9.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=7, n_estimators=900, reg_lambda=1;, score=0.966 total time=   9.6s\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'reg_lambda': [0.15, 0.2, 0.25, 0.5, 1],\n",
    "    'n_estimators': [700, 800, 900]\n",
    "}\n",
    "\n",
    "model = LGBMClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3, n_jobs=1, verbose=3)\n",
    "\n",
    "grid_result_cb= grid_search.fit(X_train_encoded, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший: 0.972616 при {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.15}\n",
      "0.863 (+/-0.006) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.15}\n",
      "0.863 (+/-0.005) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.2}\n",
      "0.861 (+/-0.005) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.25}\n",
      "0.859 (+/-0.007) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.5}\n",
      "0.856 (+/-0.006) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 1}\n",
      "0.871 (+/-0.006) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.15}\n",
      "0.871 (+/-0.007) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.2}\n",
      "0.870 (+/-0.006) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.25}\n",
      "0.868 (+/-0.007) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.5}\n",
      "0.864 (+/-0.008) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 1}\n",
      "0.878 (+/-0.008) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.15}\n",
      "0.878 (+/-0.008) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.2}\n",
      "0.877 (+/-0.008) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.25}\n",
      "0.875 (+/-0.009) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.5}\n",
      "0.871 (+/-0.008) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 1}\n",
      "0.887 (+/-0.009) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.15}\n",
      "0.887 (+/-0.010) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.2}\n",
      "0.887 (+/-0.010) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.25}\n",
      "0.884 (+/-0.011) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.5}\n",
      "0.880 (+/-0.010) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 1}\n",
      "0.895 (+/-0.010) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.15}\n",
      "0.894 (+/-0.011) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.2}\n",
      "0.894 (+/-0.010) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.25}\n",
      "0.892 (+/-0.011) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.5}\n",
      "0.888 (+/-0.012) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 1}\n",
      "0.901 (+/-0.011) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.15}\n",
      "0.901 (+/-0.011) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.2}\n",
      "0.900 (+/-0.011) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.25}\n",
      "0.898 (+/-0.012) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.5}\n",
      "0.894 (+/-0.013) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 1}\n",
      "0.943 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.15}\n",
      "0.943 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.2}\n",
      "0.943 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.25}\n",
      "0.942 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.5}\n",
      "0.938 (+/-0.012) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 1}\n",
      "0.948 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.15}\n",
      "0.948 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.2}\n",
      "0.948 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.25}\n",
      "0.947 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.5}\n",
      "0.942 (+/-0.012) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 1}\n",
      "0.952 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.15}\n",
      "0.952 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.2}\n",
      "0.951 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.25}\n",
      "0.950 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.5}\n",
      "0.946 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 1}\n",
      "0.957 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.15}\n",
      "0.956 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.2}\n",
      "0.955 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.25}\n",
      "0.954 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.5}\n",
      "0.951 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 1}\n",
      "0.960 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.15}\n",
      "0.959 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.2}\n",
      "0.959 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.25}\n",
      "0.958 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.5}\n",
      "0.954 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 1}\n",
      "0.963 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.15}\n",
      "0.962 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.2}\n",
      "0.962 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.25}\n",
      "0.961 (+/-0.010) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.5}\n",
      "0.957 (+/-0.011) with: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 1}\n",
      "0.964 (+/-0.009) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.15}\n",
      "0.963 (+/-0.008) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.2}\n",
      "0.962 (+/-0.010) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.25}\n",
      "0.961 (+/-0.010) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 0.5}\n",
      "0.958 (+/-0.010) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 700, 'reg_lambda': 1}\n",
      "0.966 (+/-0.008) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.15}\n",
      "0.966 (+/-0.009) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.2}\n",
      "0.965 (+/-0.010) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.25}\n",
      "0.964 (+/-0.009) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 0.5}\n",
      "0.961 (+/-0.009) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 800, 'reg_lambda': 1}\n",
      "0.968 (+/-0.007) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.15}\n",
      "0.967 (+/-0.008) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.2}\n",
      "0.967 (+/-0.009) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.25}\n",
      "0.966 (+/-0.008) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 0.5}\n",
      "0.963 (+/-0.008) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 900, 'reg_lambda': 1}\n",
      "0.970 (+/-0.007) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.15}\n",
      "0.969 (+/-0.009) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.2}\n",
      "0.969 (+/-0.008) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.25}\n",
      "0.968 (+/-0.009) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 0.5}\n",
      "0.966 (+/-0.010) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 700, 'reg_lambda': 1}\n",
      "0.971 (+/-0.007) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.15}\n",
      "0.971 (+/-0.009) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.2}\n",
      "0.970 (+/-0.008) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.25}\n",
      "0.969 (+/-0.009) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 0.5}\n",
      "0.967 (+/-0.009) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 800, 'reg_lambda': 1}\n",
      "0.973 (+/-0.007) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.15}\n",
      "0.972 (+/-0.008) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.2}\n",
      "0.972 (+/-0.008) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.25}\n",
      "0.971 (+/-0.008) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 0.5}\n",
      "0.969 (+/-0.010) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 900, 'reg_lambda': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Лучший: %f при %s\" % (grid_result_cb.best_score_, grid_result_cb.best_params_))\n",
    "\n",
    "means = grid_result_cb.cv_results_['mean_test_score']\n",
    "stds = grid_result_cb.cv_results_['std_test_score']\n",
    "params = grid_result_cb.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(\"%0.3f (+/-%0.03f) with: %r\" % (mean, std *  2, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC-AUC Score:  0.9551148225469729\n"
     ]
    }
   ],
   "source": [
    "best_model_cb = grid_result_cb.best_estimator_\n",
    "best_model_cb.fit(X_train_encoded, y_train)\n",
    "\n",
    "test_score = best_model_cb.score(X_test_encoded, y_test)\n",
    "\n",
    "print(\"Test ROC-AUC Score: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMC Также проявила сепбя очень хорошо. Поэтому две модели могут быть задействованы в предсказании на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_model_cb.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model_cb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_model_cb.pkl', 'rb') as file:\n",
    "    best_model_cb = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC Score:  0.8668613138686131\n"
     ]
    }
   ],
   "source": [
    "valid_score = best_model_cb.score(X_valid_encoded, y_valid)\n",
    "print(\"Validation ROC-AUC Score: \", valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_encoded = transformer.transform(test_data)\n",
    "\n",
    "predictions_svm = best_model_svm.predict(test_data_encoded)\n",
    "\n",
    "results = pd.concat([test_data_orig, pd.Series(predictions_svm, name='prediction_svm')], axis=1)\n",
    "\n",
    "results = results.drop(['tweet'], axis=1)\n",
    "results = results.rename(columns={'prediction_svm': 'label'})\n",
    "results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили файл с предсказаниями, которыйц может быть успешно отправлен на сайт. Было решение отправить предсказания SVM. Для того, тчо бы отправить LGBMC модель, нужно поменять модель _svm на _gbm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioBert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И в заключении попытка разобраться с нейронками. Я нашел модель, которая может справляться с медицинскими текстами и сделал вот такую простую архитектуру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    tokenized_texts = []\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['tweet']\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        tokenized_texts.append(inputs)\n",
    "    return tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.tsv', sep=\"\\t\")\n",
    "test_data = pd.read_csv('test.tsv', sep=\"\\t\")\n",
    "valid_data = pd.read_csv('valid.tsv', sep=\"\\t\")\n",
    "\n",
    "test_texts = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.eval()\\npredicted_labels = []\\nwith torch.no_grad():\\n    for inputs in tqdm(test_texts, desc=\"Predicting labels\", ncols=100):\\n        outputs = model(**inputs)\\n        logits = outputs.logits\\n        probabilities = torch.softmax(logits, dim=1)\\n        predicted_label = 1 if probabilities[:, 1].item() > 0.5 else 0\\n        predicted_labels.append(predicted_label)'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs in tqdm(test_texts, desc=\"Predicting labels\", ncols=100):\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        predicted_label = 1 if probabilities[:, 1].item() > 0.5 else 0\n",
    "        predicted_labels.append(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"test_data['predicted_label'] = predicted_labels\\ntest_data = test_data.drop(['tweet'], axis=1)\\ntest_data = test_data.rename(columns={'predicted_label': 'label'})\""
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['predicted_label'] = predicted_labels\n",
    "test_data = test_data.drop(['tweet'], axis=1)\n",
    "test_data = test_data.rename(columns={'predicted_label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"predicted_test_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
